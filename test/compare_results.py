#!/usr/bin/env python3
"""
å¯¹æ¯”çœŸå®GPUå’ŒFakeGPUçš„æµ‹è¯•ç»“æœ
"""

import json
import os

def print_section(title):
    print(f"\n{'='*70}")
    print(f"{title:^70}")
    print(f"{'='*70}\n")

def read_output(filename):
    if not os.path.exists(filename):
        return None
    with open(filename, 'r') as f:
        return f.read()

def main():
    print_section("Qwen2.5 æ¨ç†ç»“æœå¯¹æ¯”åˆ†æ")
    
    # è¯»å–è¾“å‡ºæ–‡ä»¶
    real_output = read_output('test/output/real_gpu_output.txt')
    fake_output = read_output('test/output/fakegpu_output.txt')
    
    # æå–å…³é”®ä¿¡æ¯
    print("ã€è®¾å¤‡ä¿¡æ¯ã€‘")
    print("-" * 70)
    
    if real_output:
        for line in real_output.split('\n'):
            if 'GPU:' in line or 'GPU Memory:' in line or 'Using device:' in line:
                print(f"  çœŸå®GPU: {line.strip()}")
    
    print()
    
    if fake_output:
        for line in fake_output.split('\n'):
            if 'GPU:' in line or 'GPU Memory:' in line or 'Using device:' in line:
                print(f"  FakeGPU: {line.strip()}")
    
    # æå–ç”Ÿæˆç»“æœ
    print("\nã€æ¨ç†ç»“æœã€‘")
    print("-" * 70)
    
    if real_output:
        for line in real_output.split('\n'):
            if 'Generated token:' in line:
                token = line.split('Generated token:')[1].strip()
                print(f"  çœŸå®GPUç”Ÿæˆ: '{token}'")
    
    if fake_output:
        for line in fake_output.split('\n'):
            if 'Generated token:' in line:
                token = line.split('Generated token:')[1].strip()
                print(f"  FakeGPUç”Ÿæˆ: '{token}'")
    
    # æµ‹è¯•çŠ¶æ€
    print("\nã€æµ‹è¯•çŠ¶æ€ã€‘")
    print("-" * 70)
    
    if real_output:
        real_passed = 'TEST PASSED' in real_output
        print(f"  çœŸå®GPU: {'âœ“ é€šè¿‡' if real_passed else 'âœ— å¤±è´¥'}")
    else:
        print(f"  çœŸå®GPU: æœªæµ‹è¯•")
    
    if fake_output:
        fake_passed = 'TEST PASSED' in fake_output
        print(f"  FakeGPU: {'âœ“ é€šè¿‡' if fake_passed else 'âœ— å¤±è´¥'}")
    
    # è¯»å–å†…å­˜æŠ¥å‘Š
    if os.path.exists('fake_gpu_report.json'):
        print("\nã€FakeGPUå†…å­˜è¿½è¸ªã€‘")
        print("-" * 70)
        with open('fake_gpu_report.json', 'r') as f:
            report = json.load(f)
        
        print(f"  è®¾å¤‡æ•°é‡: {len(report['devices'])}")
        
        has_usage = False
        for i, dev in enumerate(report['devices']):
            if dev['used_memory_peak'] > 0 or dev['used_memory_current'] > 0:
                has_usage = True
                print(f"\n  GPU {i}:")
                print(f"    åç§°: {dev['name']}")
                print(f"    æ€»å†…å­˜: {dev['total_memory'] / 1024**3:.2f} GB")
                print(f"    å³°å€¼ä½¿ç”¨: {dev['used_memory_peak'] / 1024**3:.2f} GB")
                print(f"    å½“å‰ä½¿ç”¨: {dev['used_memory_current'] / 1024**3:.2f} GB")
        
        if not has_usage:
            print("\n  æ³¨æ„: æ‰€æœ‰è®¾å¤‡çš„å†…å­˜ä½¿ç”¨å‡ä¸º0")
            print("  è¿™è¯´æ˜PyTorchå¯èƒ½ä½¿ç”¨äº†å…¶ä»–å†…å­˜ç®¡ç†æœºåˆ¶")
    
    # åˆ†æç»“è®º
    print_section("åˆ†æç»“è®º")
    
    print("âœ“ FakeGPUæˆåŠŸå®Œæˆäº†ä»¥ä¸‹ä»»åŠ¡ï¼š")
    print("  1. æ¨¡æ‹ŸCUDAè®¾å¤‡ï¼Œè®©PyTorchæ£€æµ‹åˆ°GPU")
    print("  2. åŠ è½½Qwen2.5-0.5Bæ¨¡å‹åˆ°æ¨¡æ‹ŸGPUä¸Š")
    print("  3. æ‰§è¡Œæ¨¡å‹çš„forward pass")
    print("  4. å®Œæˆtokenç”Ÿæˆæµç¨‹")
    print()
    print("âš ï¸ é¢„æœŸå·®å¼‚ï¼š")
    print("  - ç”Ÿæˆçš„tokenå†…å®¹ä¸åŒï¼ˆçœŸå®GPU: 'Hello' vs FakeGPU: '!'ï¼‰")
    print("  - è¿™æ˜¯é¢„æœŸè¡Œä¸ºï¼Œå› ä¸ºFakeGPUä¸æ‰§è¡ŒçœŸå®çš„çŸ©é˜µè¿ç®—")
    print("  - cuBLASå‡½æ•°è¿”å›éšæœºå€¼è€Œéå®é™…è®¡ç®—ç»“æœ")
    print()
    print("ğŸ¯ é¡¹ç›®ç›®æ ‡è¾¾æˆï¼š")
    print("  FakeGPUçš„è®¾è®¡ç›®æ ‡æ˜¯è®©GPUä¾èµ–çš„ä»£ç èƒ½å¤Ÿè¿è¡Œï¼Œ")
    print("  è€Œä¸æ˜¯äº§ç”Ÿæ­£ç¡®çš„è®¡ç®—ç»“æœã€‚ä»è¿™ä¸ªè§’åº¦çœ‹ï¼Œ")
    print("  FakeGPUå®Œç¾è¾¾æˆäº†è®¾è®¡ç›®æ ‡ï¼")
    print()

if __name__ == '__main__':
    main()
