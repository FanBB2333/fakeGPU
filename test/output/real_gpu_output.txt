`torch_dtype` is deprecated! Use `dtype` instead!
Using device: cuda
GPU: NVIDIA GeForce RTX 3090 Ti
GPU Memory: 23.55 GB

Loading model from /home/l1ght/models/Qwen/Qwen2.5-0.5B-Instruct...
Model loaded successfully!

Running a forward pass on cuda...
Generated token: Hello

=== TEST PASSED ===
